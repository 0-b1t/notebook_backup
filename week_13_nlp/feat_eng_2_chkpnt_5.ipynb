{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"import numpy as np\\nimport pandas as pd\\nimport sklearn\\nimport spacy\\nimport re\\nfrom nltk.corpus import gutenberg\\nimport nltk\\nimport warnings\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\\nfrom sklearn.model_selection import train_test_split\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# nltk.download(\\\"gutenberg\\\")\\n# !python -m spacy download en\";\n",
       "                var nbb_formatted_code = \"import numpy as np\\nimport pandas as pd\\nimport sklearn\\nimport spacy\\nimport re\\nfrom nltk.corpus import gutenberg\\nimport nltk\\nimport warnings\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\\nfrom sklearn.model_selection import train_test_split\\n\\nwarnings.filterwarnings(\\\"ignore\\\")\\n\\n# nltk.download(\\\"gutenberg\\\")\\n# !python -m spacy download en\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import spacy\n",
    "import re\n",
    "from nltk.corpus import gutenberg\n",
    "import nltk\n",
    "import warnings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# nltk.download(\"gutenberg\")\n",
    "# !python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# Utility function for standard text cleaning\\ndef text_cleaner(text):\\n    # Visual inspection identifies a form of punctuation that spaCy doesn't\\n    # recognize: the double dash --. Better get rid of it now!\\n    text = re.sub(r\\\"--\\\", \\\" \\\", text)\\n    text = re.sub(\\\"[\\\\[].*?[\\\\]]\\\", \\\"\\\", text)\\n    text = re.sub(r\\\"(\\\\b|\\\\s+\\\\-?|^\\\\-?)(\\\\d+|\\\\d*\\\\.\\\\d+)\\\\b\\\", \\\" \\\", text)\\n    text = \\\" \\\".join(text.split())\\n    return text\";\n",
       "                var nbb_formatted_code = \"# Utility function for standard text cleaning\\ndef text_cleaner(text):\\n    # Visual inspection identifies a form of punctuation that spaCy doesn't\\n    # recognize: the double dash --. Better get rid of it now!\\n    text = re.sub(r\\\"--\\\", \\\" \\\", text)\\n    text = re.sub(\\\"[\\\\[].*?[\\\\]]\\\", \\\"\\\", text)\\n    text = re.sub(r\\\"(\\\\b|\\\\s+\\\\-?|^\\\\-?)(\\\\d+|\\\\d*\\\\.\\\\d+)\\\\b\\\", \\\" \\\", text)\\n    text = \\\" \\\".join(text.split())\\n    return text\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Utility function for standard text cleaning\n",
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation that spaCy doesn't\n",
    "    # recognize: the double dash --. Better get rid of it now!\n",
    "    text = re.sub(r\"--\", \" \", text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = re.sub(r\"(\\b|\\s+\\-?|^\\-?)(\\d+|\\d*\\.\\d+)\\b\", \" \", text)\n",
    "    text = \" \".join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# Load and clean the data\\npersuasion = gutenberg.raw(\\\"austen-persuasion.txt\\\")\\nalice = gutenberg.raw(\\\"carroll-alice.txt\\\")\\n\\n# The chapter indicator is idiosyncratic\\npersuasion = re.sub(r\\\"Chapter \\\\d+\\\", \\\"\\\", persuasion)\\nalice = re.sub(r\\\"CHAPTER .*\\\", \\\"\\\", alice)\\n\\nalice = text_cleaner(alice)\\npersuasion = text_cleaner(persuasion)\";\n",
       "                var nbb_formatted_code = \"# Load and clean the data\\npersuasion = gutenberg.raw(\\\"austen-persuasion.txt\\\")\\nalice = gutenberg.raw(\\\"carroll-alice.txt\\\")\\n\\n# The chapter indicator is idiosyncratic\\npersuasion = re.sub(r\\\"Chapter \\\\d+\\\", \\\"\\\", persuasion)\\nalice = re.sub(r\\\"CHAPTER .*\\\", \\\"\\\", alice)\\n\\nalice = text_cleaner(alice)\\npersuasion = text_cleaner(persuasion)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load and clean the data\n",
    "persuasion = gutenberg.raw(\"austen-persuasion.txt\")\n",
    "alice = gutenberg.raw(\"carroll-alice.txt\")\n",
    "\n",
    "# The chapter indicator is idiosyncratic\n",
    "persuasion = re.sub(r\"Chapter \\d+\", \"\", persuasion)\n",
    "alice = re.sub(r\"CHAPTER .*\", \"\", alice)\n",
    "\n",
    "alice = text_cleaner(alice)\n",
    "persuasion = text_cleaner(persuasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# Parse the cleaned novels. This can take some time.\\nnlp = spacy.load(\\\"en\\\")\\nalice_doc = nlp(alice)\\npersuasion_doc = nlp(persuasion)\";\n",
       "                var nbb_formatted_code = \"# Parse the cleaned novels. This can take some time.\\nnlp = spacy.load(\\\"en\\\")\\nalice_doc = nlp(alice)\\npersuasion_doc = nlp(persuasion)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Parse the cleaned novels. This can take some time.\n",
    "nlp = spacy.load(\"en\")\n",
    "alice_doc = nlp(alice)\n",
    "persuasion_doc = nlp(persuasion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Alice, was, beginning, to, get, very, tired, ...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(So, she, was, considering, in, her, own, mind...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(There, was, nothing, so, VERY, remarkable, in...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Oh, dear, !)</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   author\n",
       "0  (Alice, was, beginning, to, get, very, tired, ...  Carroll\n",
       "1  (So, she, was, considering, in, her, own, mind...  Carroll\n",
       "2  (There, was, nothing, so, VERY, remarkable, in...  Carroll\n",
       "3                                      (Oh, dear, !)  Carroll\n",
       "4                                      (Oh, dear, !)  Carroll"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"# Group into sentences\\nalice_sents = [[sent, \\\"Carroll\\\"] for sent in alice_doc.sents]\\npersuasion_sents = [[sent, \\\"Austen\\\"] for sent in persuasion_doc.sents]\\n\\n# Combine the sentences from the two novels into one DataFrame\\nsentences = pd.DataFrame(alice_sents + persuasion_sents, columns=[\\\"text\\\", \\\"author\\\"])\\nsentences.head()\";\n",
       "                var nbb_formatted_code = \"# Group into sentences\\nalice_sents = [[sent, \\\"Carroll\\\"] for sent in alice_doc.sents]\\npersuasion_sents = [[sent, \\\"Austen\\\"] for sent in persuasion_doc.sents]\\n\\n# Combine the sentences from the two novels into one DataFrame\\nsentences = pd.DataFrame(alice_sents + persuasion_sents, columns=[\\\"text\\\", \\\"author\\\"])\\nsentences.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Group into sentences\n",
    "alice_sents = [[sent, \"Carroll\"] for sent in alice_doc.sents]\n",
    "persuasion_sents = [[sent, \"Austen\"] for sent in persuasion_doc.sents]\n",
    "\n",
    "# Combine the sentences from the two novels into one DataFrame\n",
    "sentences = pd.DataFrame(alice_sents + persuasion_sents, columns=[\"text\", \"author\"])\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"# Get rid of stop words and punctuation,\\n# and lemmatize the tokens\\nfor i, sentence in enumerate(sentences[\\\"text\\\"]):\\n    sentences.loc[i, \\\"text\\\"] = \\\" \\\".join(\\n        [token.lemma_ for token in sentence if not token.is_punct and not token.is_stop]\\n    )\";\n",
       "                var nbb_formatted_code = \"# Get rid of stop words and punctuation,\\n# and lemmatize the tokens\\nfor i, sentence in enumerate(sentences[\\\"text\\\"]):\\n    sentences.loc[i, \\\"text\\\"] = \\\" \\\".join(\\n        [token.lemma_ for token in sentence if not token.is_punct and not token.is_stop]\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get rid of stop words and punctuation,\n",
    "# and lemmatize the tokens\n",
    "for i, sentence in enumerate(sentences[\"text\"]):\n",
    "    sentences.loc[i, \"text\"] = \" \".join(\n",
    "        [token.lemma_ for token in sentence if not token.is_punct and not token.is_stop]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice begin tired sit sister bank have twice p...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>consider mind hot day feel sleepy stupid pleas...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>remarkable Alice think way hear Rabbit</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oh dear</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oh dear</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   author\n",
       "0  Alice begin tired sit sister bank have twice p...  Carroll\n",
       "1  consider mind hot day feel sleepy stupid pleas...  Carroll\n",
       "2             remarkable Alice think way hear Rabbit  Carroll\n",
       "3                                            oh dear  Carroll\n",
       "4                                            oh dear  Carroll"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"sentences.head()\";\n",
       "                var nbb_formatted_code = \"sentences.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alarm</th>\n",
       "      <th>belong</th>\n",
       "      <th>dim</th>\n",
       "      <th>distinguished</th>\n",
       "      <th>domestic</th>\n",
       "      <th>dread</th>\n",
       "      <th>finis</th>\n",
       "      <th>friend</th>\n",
       "      <th>future</th>\n",
       "      <th>glory</th>\n",
       "      <th>...</th>\n",
       "      <th>sailor</th>\n",
       "      <th>sunshine</th>\n",
       "      <th>tax</th>\n",
       "      <th>tenderness</th>\n",
       "      <th>virtue</th>\n",
       "      <th>war</th>\n",
       "      <th>wife</th>\n",
       "      <th>wish</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.341426</td>\n",
       "      <td>0.341426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341426</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.341426</td>\n",
       "      <td>Alice begin tired sit sister bank have twice p...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.261906</td>\n",
       "      <td>0.261906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261906</td>\n",
       "      <td>0.261906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261906</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>consider mind hot day feel sleepy stupid pleas...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>remarkable Alice think way hear Rabbit</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>oh dear</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>oh dear</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      alarm    belong       dim  distinguished  domestic     dread  finis  \\\n",
       "0  0.000000  0.000000  0.341426       0.000000  0.000000  0.341426    0.0   \n",
       "1  0.261906  0.261906  0.000000       0.261906  0.261906  0.000000    0.0   \n",
       "2  0.000000  0.000000  0.000000       0.000000  0.000000  0.000000    1.0   \n",
       "3       NaN       NaN       NaN            NaN       NaN       NaN    NaN   \n",
       "4       NaN       NaN       NaN            NaN       NaN       NaN    NaN   \n",
       "\n",
       "     friend    future     glory  ...    sailor  sunshine       tax  \\\n",
       "0  0.341426  0.341426  0.000000  ...  0.000000  0.341426  0.000000   \n",
       "1  0.000000  0.000000  0.261906  ...  0.261906  0.000000  0.261906   \n",
       "2  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000   \n",
       "3       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "4       NaN       NaN       NaN  ...       NaN       NaN       NaN   \n",
       "\n",
       "   tenderness    virtue       war      wife      wish  \\\n",
       "0    0.341426  0.000000  0.341426  0.000000  0.341426   \n",
       "1    0.000000  0.261906  0.000000  0.261906  0.000000   \n",
       "2    0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3         NaN       NaN       NaN       NaN       NaN   \n",
       "4         NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "                                                text   author  \n",
       "0  Alice begin tired sit sister bank have twice p...  Carroll  \n",
       "1  consider mind hot day feel sleepy stupid pleas...  Carroll  \n",
       "2             remarkable Alice think way hear Rabbit  Carroll  \n",
       "3                                            oh dear  Carroll  \n",
       "4                                            oh dear  Carroll  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"from sklearn.feature_extraction.text import TfidfVectorizer\\n\\nvectorizer = TfidfVectorizer(\\n    max_df=0.7, min_df=1, use_idf=True, norm=u\\\"l2\\\", smooth_idf=True\\n)\\n\\n\\n# Applying the vectorizer\\nX = vectorizer.fit_transform(sentences[\\\"text\\\"][-3:])\\n\\ntfidf_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\\nlast_3_sentences = pd.concat([tfidf_df, sentences[[\\\"text\\\", \\\"author\\\"]]], axis=1)\\n\\n# Keep in mind that log base 2 of 1 is 0,\\n# so a TF-IDF score of 0 indicates that the word was present once in that sentence.\\nlast_3_sentences.head()\";\n",
       "                var nbb_formatted_code = \"from sklearn.feature_extraction.text import TfidfVectorizer\\n\\nvectorizer = TfidfVectorizer(\\n    max_df=0.7, min_df=1, use_idf=True, norm=u\\\"l2\\\", smooth_idf=True\\n)\\n\\n\\n# Applying the vectorizer\\nX = vectorizer.fit_transform(sentences[\\\"text\\\"][-3:])\\n\\ntfidf_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\\nlast_3_sentences = pd.concat([tfidf_df, sentences[[\\\"text\\\", \\\"author\\\"]]], axis=1)\\n\\n# Keep in mind that log base 2 of 1 is 0,\\n# so a TF-IDF score of 0 indicates that the word was present once in that sentence.\\nlast_3_sentences.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_df=0.7, min_df=1, use_idf=True, norm=u\"l2\", smooth_idf=True\n",
    ")\n",
    "\n",
    "\n",
    "# Applying the vectorizer\n",
    "X = vectorizer.fit_transform(sentences[\"text\"][-3:])\n",
    "\n",
    "tfidf_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "last_3_sentences = pd.concat([tfidf_df, sentences[[\"text\", \"author\"]]], axis=1)\n",
    "\n",
    "# Keep in mind that log base 2 of 1 is 0,\n",
    "# so a TF-IDF score of 0 indicates that the word was present once in that sentence.\n",
    "last_3_sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abide</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>able bear</th>\n",
       "      <th>able persuade</th>\n",
       "      <th>abominate</th>\n",
       "      <th>abroad</th>\n",
       "      <th>absence</th>\n",
       "      <th>absence home</th>\n",
       "      <th>absent</th>\n",
       "      <th>...</th>\n",
       "      <th>young people</th>\n",
       "      <th>young person</th>\n",
       "      <th>young sister</th>\n",
       "      <th>young woman</th>\n",
       "      <th>youth</th>\n",
       "      <th>youth say</th>\n",
       "      <th>zeal</th>\n",
       "      <th>zealous</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Alice begin tired sit sister bank have twice p...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>consider mind hot day feel sleepy stupid pleas...</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>remarkable Alice think way hear Rabbit</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>oh dear</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>oh dear</td>\n",
       "      <td>Carroll</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5489 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abide  ability  able  able bear  able persuade  abominate  abroad  absence  \\\n",
       "0    0.0      0.0   0.0        0.0            0.0        0.0     0.0      0.0   \n",
       "1    0.0      0.0   0.0        0.0            0.0        0.0     0.0      0.0   \n",
       "2    0.0      0.0   0.0        0.0            0.0        0.0     0.0      0.0   \n",
       "3    0.0      0.0   0.0        0.0            0.0        0.0     0.0      0.0   \n",
       "4    0.0      0.0   0.0        0.0            0.0        0.0     0.0      0.0   \n",
       "\n",
       "   absence home  absent  ...  young people  young person  young sister  \\\n",
       "0           0.0     0.0  ...           0.0           0.0           0.0   \n",
       "1           0.0     0.0  ...           0.0           0.0           0.0   \n",
       "2           0.0     0.0  ...           0.0           0.0           0.0   \n",
       "3           0.0     0.0  ...           0.0           0.0           0.0   \n",
       "4           0.0     0.0  ...           0.0           0.0           0.0   \n",
       "\n",
       "   young woman  youth  youth say  zeal  zealous  \\\n",
       "0          0.0    0.0        0.0   0.0      0.0   \n",
       "1          0.0    0.0        0.0   0.0      0.0   \n",
       "2          0.0    0.0        0.0   0.0      0.0   \n",
       "3          0.0    0.0        0.0   0.0      0.0   \n",
       "4          0.0    0.0        0.0   0.0      0.0   \n",
       "\n",
       "                                                text   author  \n",
       "0  Alice begin tired sit sister bank have twice p...  Carroll  \n",
       "1  consider mind hot day feel sleepy stupid pleas...  Carroll  \n",
       "2             remarkable Alice think way hear Rabbit  Carroll  \n",
       "3                                            oh dear  Carroll  \n",
       "4                                            oh dear  Carroll  \n",
       "\n",
       "[5 rows x 5489 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"vectorizer = TfidfVectorizer(\\n    max_df=0.5, min_df=2, use_idf=True, norm=u'l2', smooth_idf=True, ngram_range=(1,2))\\n\\n\\n# Applying the vectorizer\\nX = vectorizer.fit_transform(sentences[\\\"text\\\"])\\n\\ntfidf_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\\nsentences = pd.concat([tfidf_df, sentences[[\\\"text\\\", \\\"author\\\"]]], axis=1)\\n\\n# Keep in mind that log base 2 of 1 is 0,\\n# so a TF-IDF score of 0 indicates that the word was present once in that sentence.\\nsentences.head()\";\n",
       "                var nbb_formatted_code = \"vectorizer = TfidfVectorizer(\\n    max_df=0.5, min_df=2, use_idf=True, norm=u\\\"l2\\\", smooth_idf=True, ngram_range=(1, 2)\\n)\\n\\n\\n# Applying the vectorizer\\nX = vectorizer.fit_transform(sentences[\\\"text\\\"])\\n\\ntfidf_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\\nsentences = pd.concat([tfidf_df, sentences[[\\\"text\\\", \\\"author\\\"]]], axis=1)\\n\\n# Keep in mind that log base 2 of 1 is 0,\\n# so a TF-IDF score of 0 indicates that the word was present once in that sentence.\\nsentences.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    max_df=0.5, min_df=2, use_idf=True, norm=u\"l2\", smooth_idf=True, ngram_range=(1, 2)\n",
    ")\n",
    "\n",
    "\n",
    "# Applying the vectorizer\n",
    "X = vectorizer.fit_transform(sentences[\"text\"])\n",
    "\n",
    "tfidf_df = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "sentences = pd.concat([tfidf_df, sentences[[\"text\", \"author\"]]], axis=1)\n",
    "\n",
    "# Keep in mind that log base 2 of 1 is 0,\n",
    "# so a TF-IDF score of 0 indicates that the word was present once in that sentence.\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------Logistic Regression Scores----------------------\n",
      "Training set score: 0.912696063924238\n",
      "\n",
      "Test set score: 0.8717265867731913\n",
      "----------------------Random Forest Scores----------------------\n",
      "Training set score: 0.9786919206865937\n",
      "\n",
      "Test set score: 0.873058144695961\n",
      "----------------------Gradient Boosting Scores----------------------\n",
      "Training set score: 0.8490677715300384\n",
      "\n",
      "Test set score: 0.831779849090102\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"Y = sentences['author']\\nX = np.array(sentences.drop(['text','author'], 1))\\n\\n# Split the dataset into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=123)\\n\\n# Models\\nlr = LogisticRegression()\\nrfc = RandomForestClassifier()\\ngbc = GradientBoostingClassifier()\\n\\nlr.fit(X_train, y_train)\\nrfc.fit(X_train, y_train)\\ngbc.fit(X_train, y_train)\\n\\nprint(\\\"----------------------Logistic Regression Scores----------------------\\\")\\nprint('Training set score:', lr.score(X_train, y_train))\\nprint('\\\\nTest set score:', lr.score(X_test, y_test))\\n\\nprint(\\\"----------------------Random Forest Scores----------------------\\\")\\nprint('Training set score:', rfc.score(X_train, y_train))\\nprint('\\\\nTest set score:', rfc.score(X_test, y_test))\\n\\nprint(\\\"----------------------Gradient Boosting Scores----------------------\\\")\\nprint('Training set score:', gbc.score(X_train, y_train))\\nprint('\\\\nTest set score:', gbc.score(X_test, y_test))\";\n",
       "                var nbb_formatted_code = \"Y = sentences[\\\"author\\\"]\\nX = np.array(sentences.drop([\\\"text\\\", \\\"author\\\"], 1))\\n\\n# Split the dataset into training and test sets\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, Y, test_size=0.4, random_state=123\\n)\\n\\n# Models\\nlr = LogisticRegression()\\nrfc = RandomForestClassifier()\\ngbc = GradientBoostingClassifier()\\n\\nlr.fit(X_train, y_train)\\nrfc.fit(X_train, y_train)\\ngbc.fit(X_train, y_train)\\n\\nprint(\\\"----------------------Logistic Regression Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", lr.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", lr.score(X_test, y_test))\\n\\nprint(\\\"----------------------Random Forest Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", rfc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", rfc.score(X_test, y_test))\\n\\nprint(\\\"----------------------Gradient Boosting Scores----------------------\\\")\\nprint(\\\"Training set score:\\\", gbc.score(X_train, y_train))\\nprint(\\\"\\\\nTest set score:\\\", gbc.score(X_test, y_test))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y = sentences[\"author\"]\n",
    "X = np.array(sentences.drop([\"text\", \"author\"], 1))\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.4, random_state=123\n",
    ")\n",
    "\n",
    "# Models\n",
    "lr = LogisticRegression()\n",
    "rfc = RandomForestClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "rfc.fit(X_train, y_train)\n",
    "gbc.fit(X_train, y_train)\n",
    "\n",
    "print(\"----------------------Logistic Regression Scores----------------------\")\n",
    "print(\"Training set score:\", lr.score(X_train, y_train))\n",
    "print(\"\\nTest set score:\", lr.score(X_test, y_test))\n",
    "\n",
    "print(\"----------------------Random Forest Scores----------------------\")\n",
    "print(\"Training set score:\", rfc.score(X_train, y_train))\n",
    "print(\"\\nTest set score:\", rfc.score(X_test, y_test))\n",
    "\n",
    "print(\"----------------------Gradient Boosting Scores----------------------\")\n",
    "print(\"Training set score:\", gbc.score(X_train, y_train))\n",
    "print(\"\\nTest set score:\", gbc.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------Logistic Regression Scores----------------------\n",
    "# Training set score: 0.8494825964252116\n",
    "\n",
    "# Test set score: 0.7986829727187206\n",
    "# ----------------------Random Forest Scores----------------------\n",
    "# Training set score: 0.9357165255566008\n",
    "\n",
    "# Test set score: 0.8419567262464722\n",
    "# ----------------------Gradient Boosting Scores----------------------\n",
    "# Training set score: 0.8143618689244277\n",
    "\n",
    "# Test set score: 0.7958607714016933\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like having both is better on all fronts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
