{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You now have a fairly substantial starting toolbox of supervised learning methods that you can use to tackle a host of exciting problems. To make sure that all of these ideas are organized in your mind, go through the list of problems below. For each, identify which supervised learning method (or methods) would be best for addressing that particular problem. Explain your reasoning and discuss your answers with your mentor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using data from the last 20 Olympics, predict the running times of prospective Olympic sprinters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difficult to say without knowing exactly what data we're receiving. This seems like it could be solved pretty easily with linear regression. Although, if we're taking things like height and weight into consideration, there may not be a strictly linear relationship/correlation with the target. SVR with a non-linear kernel would be good. If it's a lot of categorical data, I would probably start with forest regression for gradient boosting decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You have more features (columns) than rows in your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select K Best seems like it might be helpful. This one is kind of tough. \n",
    "PCA\n",
    "Lasso/Ridge regeression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Identify the most important characteristic for predicting the likelihood of being jailed before age 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually OLS stands out as the easiest way to see the importance of coefficients, however if the data doesn't meet the strict assumptions, it may actually not tell us the correct answer. Using gradient boosting tree classifiers or just a flat out decision tree classifier could be useful depending on the shape of the data. There's also looking at a correlation matrix to see what feature shows the most separation betweeen outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement a filter to highlight emails that might be important to the recipient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't immediately obvious, especially since we haven't gone over NLP yet. I would probably mainly look at email address and how often they opened one from that url tag or address in particular. Maybe character count would come into play? Time of day? Given that data, KNN sounds like a good candidate to begin with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You have more than 1,000 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA. Also, checking NA's to see if any of the columns have massive amounts of data missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict whether someone who adds items to their cart on a website will purchase the items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is one where I doubt there's a strictly linear relationship between features. KNN or forest classification/decision tree seems good. If there is a fair amount of numerical data than SVM could be useful. We're a bit fresh on gradient boosting so it's tough to know which of those methods would be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Your dataset dimensions are 982400x500."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin, I would take a subsample and maybe stratify by the target variable. From there, PCA is probably fitting. Also, as before, look to see if any columns are missing a large amount of data and drop those. Definitely drop rows with missing data. At least for the initial model stage. It would be worth trying to hold on to those data points once we have a better idea of what model will work best for the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify faces in an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a lack of knowledge in computer vision, hard to really say. KNN seems like it could be either really good or really terrible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict which of three flavors of ice cream will be most popular with boys versus girls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would maybe split it into two completely different models. One for boys and one for girls. I'm having a hard time thinking of what this data would even look like. Using some kind of classifier, then predicting the probability for each observation and taking the three highest means of all flavors? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
