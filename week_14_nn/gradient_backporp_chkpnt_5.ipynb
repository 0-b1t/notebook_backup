{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import numpy as np\\nimport pandas as pd\\nimport matplotlib\\nimport tensorflow as tf\\n\\ntf.debugging.set_log_device_placement(True)\\n\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\n\\nfrom sklearn.model_selection import train_test_split\\nfrom tensorflow.keras.datasets import mnist\\nfrom tensorflow.keras.utils import to_categorical\\nfrom tensorflow.keras.optimizers import SGD, RMSprop, Adam\";\n",
       "                var nbb_formatted_code = \"import numpy as np\\nimport pandas as pd\\nimport matplotlib\\nimport tensorflow as tf\\n\\ntf.debugging.set_log_device_placement(True)\\n\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\n\\nfrom sklearn.model_selection import train_test_split\\nfrom tensorflow.keras.datasets import mnist\\nfrom tensorflow.keras.utils import to_categorical\\nfrom tensorflow.keras.optimizers import SGD, RMSprop, Adam\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "\n",
      "[[ 8.  5.]\n",
      " [20. 13.]]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"import os\\n\\ntf.compat.v1.disable_eager_execution()\\n\\nhello = tf.constant(\\\"Hello, TensorFlow!\\\")\\n\\n# sess = tf.compat.v1.Session()\\n\\nos.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"0\\\"  # You need to tell CUDA\\n# which GPU you'd like to use. if you have one GPU probably your GPU is '0'with tf.device('/gpu:0'):\\na = tf.constant([1.0, 2.0, 3.0, 4.0], shape=[2, 2], name=\\\"a\\\")\\nb = tf.constant([4.0, 3.0, 2.0, 1.0], shape=[2, 2], name=\\\"b\\\")\\nc = tf.matmul(a, b)\\n# with tf.compat.v1.Session() as sess:\\n#     print(sess.run(c))\\n\\nsess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\\n# Runs the op.\\nprint(sess.run(c))\";\n",
       "                var nbb_formatted_code = \"import os\\n\\ntf.compat.v1.disable_eager_execution()\\n\\nhello = tf.constant(\\\"Hello, TensorFlow!\\\")\\n\\n# sess = tf.compat.v1.Session()\\n\\nos.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"0\\\"  # You need to tell CUDA\\n# which GPU you'd like to use. if you have one GPU probably your GPU is '0'with tf.device('/gpu:0'):\\na = tf.constant([1.0, 2.0, 3.0, 4.0], shape=[2, 2], name=\\\"a\\\")\\nb = tf.constant([4.0, 3.0, 2.0, 1.0], shape=[2, 2], name=\\\"b\\\")\\nc = tf.matmul(a, b)\\n# with tf.compat.v1.Session() as sess:\\n#     print(sess.run(c))\\n\\nsess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\\n# Runs the op.\\nprint(sess.run(c))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "hello = tf.constant(\"Hello, TensorFlow!\")\n",
    "\n",
    "# sess = tf.compat.v1.Session()\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # You need to tell CUDA\n",
    "# which GPU you'd like to use. if you have one GPU probably your GPU is '0'with tf.device('/gpu:0'):\n",
    "a = tf.constant([1.0, 2.0, 3.0, 4.0], shape=[2, 2], name=\"a\")\n",
    "b = tf.constant([4.0, 3.0, 2.0, 1.0], shape=[2, 2], name=\"b\")\n",
    "c = tf.matmul(a, b)\n",
    "# with tf.compat.v1.Session() as sess:\n",
    "#     print(sess.run(c))\n",
    "\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
    "# Runs the op.\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"def build_model(\\n    input_dim,\\n    output_dim=1,\\n    layer_nodes=[64, 32, 32],\\n    activation_function=\\\"relu\\\",\\n    output_function=\\\"sigmoid\\\",\\n):\\n    model = Sequential()\\n    model.add(\\n        Dense(layer_nodes[0], input_dim=input_dim, activation=activation_function)\\n    )\\n    for i in range(1, len(layer_nodes)):\\n        model.add(Dense(layer_nodes[i], activation=activation_function))\\n\\n    model.add(Dense(output_dim, activation=output_function))\\n\\n    return model\";\n",
       "                var nbb_formatted_code = \"def build_model(\\n    input_dim,\\n    output_dim=1,\\n    layer_nodes=[64, 32, 32],\\n    activation_function=\\\"relu\\\",\\n    output_function=\\\"sigmoid\\\",\\n):\\n    model = Sequential()\\n    model.add(\\n        Dense(layer_nodes[0], input_dim=input_dim, activation=activation_function)\\n    )\\n    for i in range(1, len(layer_nodes)):\\n        model.add(Dense(layer_nodes[i], activation=activation_function))\\n\\n    model.add(Dense(output_dim, activation=output_function))\\n\\n    return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_model(\n",
    "    input_dim,\n",
    "    output_dim=1,\n",
    "    layer_nodes=[64, 32, 32],\n",
    "    activation_function=\"relu\",\n",
    "    output_function=\"sigmoid\",\n",
    "):\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Dense(layer_nodes[0], input_dim=input_dim, activation=activation_function)\n",
    "    )\n",
    "    for i in range(1, len(layer_nodes)):\n",
    "        model.add(Dense(layer_nodes[i], activation=activation_function))\n",
    "\n",
    "    model.add(Dense(output_dim, activation=output_function))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"(X_train, y_train), (X_test, y_test) = mnist.load_data()\\n\\ninput_dim = 784  # 28*28\\noutput_dim = nb_classes = 10\\nbatch_size = 128\\nnb_epoch = 20\\n\\nX_train = X_train.reshape(60000, input_dim)\\nX_test = X_test.reshape(10000, input_dim)\\nX_train = X_train.astype(\\\"float32\\\")\\nX_test = X_test.astype(\\\"float32\\\")\\nX_train /= 255\\nX_test /= 255\\n\\n\\ny_train = to_categorical(y_train, nb_classes)\\ny_test = to_categorical(y_test, nb_classes)\";\n",
       "                var nbb_formatted_code = \"(X_train, y_train), (X_test, y_test) = mnist.load_data()\\n\\ninput_dim = 784  # 28*28\\noutput_dim = nb_classes = 10\\nbatch_size = 128\\nnb_epoch = 20\\n\\nX_train = X_train.reshape(60000, input_dim)\\nX_test = X_test.reshape(10000, input_dim)\\nX_train = X_train.astype(\\\"float32\\\")\\nX_test = X_test.astype(\\\"float32\\\")\\nX_train /= 255\\nX_test /= 255\\n\\n\\ny_train = to_categorical(y_train, nb_classes)\\ny_test = to_categorical(y_test, nb_classes)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "input_dim = 784  # 28*28\n",
    "output_dim = nb_classes = 10\n",
    "batch_size = 128\n",
    "nb_epoch = 20\n",
    "\n",
    "X_train = X_train.reshape(60000, input_dim)\n",
    "X_test = X_test.reshape(10000, input_dim)\n",
    "X_train = X_train.astype(\"float32\")\n",
    "X_test = X_test.astype(\"float32\")\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "\n",
    "y_train = to_categorical(y_train, nb_classes)\n",
    "y_test = to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "\n",
      "Epoch 1/20\n",
      "59816/60000 [============================>.] - ETA: 0s - loss: 0.1665 - accuracy: 0.9192WARNING:tensorflow:From C:\\Users\\b1t\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py:2048: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.1664 - accuracy: 0.9193 - val_loss: 0.0901 - val_accuracy: 0.9557\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.0940 - accuracy: 0.9534 - val_loss: 0.0910 - val_accuracy: 0.9543\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.0800 - accuracy: 0.9602 - val_loss: 0.0800 - val_accuracy: 0.9604\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 6s 99us/sample - loss: 0.0715 - accuracy: 0.9644 - val_loss: 0.0747 - val_accuracy: 0.9624\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.0663 - accuracy: 0.9669 - val_loss: 0.0774 - val_accuracy: 0.9612\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 6s 93us/sample - loss: 0.0606 - accuracy: 0.9699 - val_loss: 0.0677 - val_accuracy: 0.9660\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.0622 - accuracy: 0.9688 - val_loss: 0.0618 - val_accuracy: 0.9686\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 6s 96us/sample - loss: 0.0597 - accuracy: 0.9701 - val_loss: 0.0756 - val_accuracy: 0.9622\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.0598 - accuracy: 0.9701 - val_loss: 0.0638 - val_accuracy: 0.9681\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.0577 - accuracy: 0.9711 - val_loss: 0.0605 - val_accuracy: 0.9696\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.0522 - accuracy: 0.9738 - val_loss: 0.0554 - val_accuracy: 0.9719\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.0537 - accuracy: 0.9732 - val_loss: 0.0611 - val_accuracy: 0.9693\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 6s 93us/sample - loss: 0.0505 - accuracy: 0.9748 - val_loss: 0.0642 - val_accuracy: 0.9675\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.0532 - accuracy: 0.9733 - val_loss: 0.0550 - val_accuracy: 0.9723\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.0496 - accuracy: 0.9752 - val_loss: 0.0816 - val_accuracy: 0.9591\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 5s 80us/sample - loss: 0.0531 - accuracy: 0.9735 - val_loss: 0.0623 - val_accuracy: 0.9688\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.0495 - accuracy: 0.9751 - val_loss: 0.0622 - val_accuracy: 0.9689\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0520 - accuracy: 0.9739 - val_loss: 0.0728 - val_accuracy: 0.9637\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 5s 81us/sample - loss: 0.0517 - accuracy: 0.9741 - val_loss: 0.0598 - val_accuracy: 0.9700\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 5s 84us/sample - loss: 0.0497 - accuracy: 0.9750 - val_loss: 0.0604 - val_accuracy: 0.9697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25c8eceaa00>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"model = build_model(\\n    input_dim=X_train.shape[1],\\n    output_dim=y_train.shape[1],\\n    layer_nodes=[128, 64],\\n    activation_function=\\\"relu\\\",\\n    output_function=\\\"softmax\\\",\\n)\\n\\nmodel.compile(optimizer=\\\"adam\\\", loss=\\\"categorical_hinge\\\", metrics=[\\\"accuracy\\\"])\\n\\nmodel.fit(\\n    X_train,\\n    y_train,\\n    validation_data=(X_test, y_test),\\n    batch_size=8,\\n    epochs=20,\\n    verbose=1,\\n)\";\n",
       "                var nbb_formatted_code = \"model = build_model(\\n    input_dim=X_train.shape[1],\\n    output_dim=y_train.shape[1],\\n    layer_nodes=[128, 64],\\n    activation_function=\\\"relu\\\",\\n    output_function=\\\"softmax\\\",\\n)\\n\\nmodel.compile(optimizer=\\\"adam\\\", loss=\\\"categorical_hinge\\\", metrics=[\\\"accuracy\\\"])\\n\\nmodel.fit(\\n    X_train,\\n    y_train,\\n    validation_data=(X_test, y_test),\\n    batch_size=8,\\n    epochs=20,\\n    verbose=1,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = build_model(\n",
    "    input_dim=X_train.shape[1],\n",
    "    output_dim=y_train.shape[1],\n",
    "    layer_nodes=[128, 64],\n",
    "    activation_function=\"relu\",\n",
    "    output_function=\"softmax\",\n",
    ")\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_hinge\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=8,\n",
    "    epochs=20,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 16us/sample - loss: 0.2584 - accuracy: 0.8834 - val_loss: 0.1306 - val_accuracy: 0.9395\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1196 - accuracy: 0.9450 - val_loss: 0.1010 - val_accuracy: 0.9539\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0939 - accuracy: 0.9566 - val_loss: 0.0842 - val_accuracy: 0.9602\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.0753 - accuracy: 0.9654 - val_loss: 0.0808 - val_accuracy: 0.9622\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.0637 - accuracy: 0.9706 - val_loss: 0.0667 - val_accuracy: 0.9690\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0561 - accuracy: 0.9740 - val_loss: 0.0651 - val_accuracy: 0.9692\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0494 - accuracy: 0.9774 - val_loss: 0.0623 - val_accuracy: 0.9711\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.0439 - accuracy: 0.9797 - val_loss: 0.0581 - val_accuracy: 0.9726\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.0407 - accuracy: 0.9811 - val_loss: 0.0547 - val_accuracy: 0.9742\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0369 - accuracy: 0.9830 - val_loss: 0.0576 - val_accuracy: 0.9721\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0345 - accuracy: 0.9842 - val_loss: 0.0635 - val_accuracy: 0.9694\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0314 - accuracy: 0.9854 - val_loss: 0.0541 - val_accuracy: 0.9740\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0302 - accuracy: 0.9861 - val_loss: 0.0550 - val_accuracy: 0.9737\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0274 - accuracy: 0.9872 - val_loss: 0.0534 - val_accuracy: 0.9745\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.0261 - accuracy: 0.9880 - val_loss: 0.0500 - val_accuracy: 0.9747\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.0252 - accuracy: 0.9881 - val_loss: 0.0517 - val_accuracy: 0.9751\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.0249 - accuracy: 0.9882 - val_loss: 0.0501 - val_accuracy: 0.9757\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.0222 - accuracy: 0.9897 - val_loss: 0.0492 - val_accuracy: 0.9756\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.0222 - accuracy: 0.9895 - val_loss: 0.0491 - val_accuracy: 0.9758\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 13us/sample - loss: 0.0206 - accuracy: 0.9904 - val_loss: 0.0505 - val_accuracy: 0.9753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25ca1654e80>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"model = build_model(\\n    input_dim=X_train.shape[1],\\n    output_dim=y_train.shape[1],\\n    layer_nodes=[128, 64],\\n    activation_function=\\\"relu\\\",\\n    output_function=\\\"softmax\\\",\\n)\\n\\nmodel.compile(optimizer=\\\"adam\\\", loss=\\\"categorical_hinge\\\", metrics=[\\\"accuracy\\\"])\\n\\nmodel.fit(\\n    X_train,\\n    y_train,\\n    validation_data=(X_test, y_test),\\n    batch_size=128,\\n    epochs=20,\\n    verbose=1,\\n)\";\n",
       "                var nbb_formatted_code = \"model = build_model(\\n    input_dim=X_train.shape[1],\\n    output_dim=y_train.shape[1],\\n    layer_nodes=[128, 64],\\n    activation_function=\\\"relu\\\",\\n    output_function=\\\"softmax\\\",\\n)\\n\\nmodel.compile(optimizer=\\\"adam\\\", loss=\\\"categorical_hinge\\\", metrics=[\\\"accuracy\\\"])\\n\\nmodel.fit(\\n    X_train,\\n    y_train,\\n    validation_data=(X_test, y_test),\\n    batch_size=128,\\n    epochs=20,\\n    verbose=1,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = build_model(\n",
    "    input_dim=X_train.shape[1],\n",
    "    output_dim=y_train.shape[1],\n",
    "    layer_nodes=[128, 64],\n",
    "    activation_function=\"relu\",\n",
    "    output_function=\"softmax\",\n",
    ")\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_hinge\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=128,\n",
    "    epochs=20,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 35us/sample - loss: 0.1874 - accuracy: 0.9149 - val_loss: 0.1041 - val_accuracy: 0.9507\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0907 - accuracy: 0.9567 - val_loss: 0.0879 - val_accuracy: 0.9588\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 2s 28us/sample - loss: 0.0701 - accuracy: 0.9663 - val_loss: 0.0683 - val_accuracy: 0.9672\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0585 - accuracy: 0.9720 - val_loss: 0.0656 - val_accuracy: 0.9676\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0522 - accuracy: 0.9750 - val_loss: 0.0650 - val_accuracy: 0.9683\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0459 - accuracy: 0.9779 - val_loss: 0.0595 - val_accuracy: 0.9707\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0425 - accuracy: 0.9793 - val_loss: 0.0560 - val_accuracy: 0.9725\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 0.0393 - accuracy: 0.9807 - val_loss: 0.0512 - val_accuracy: 0.9750\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 2s 31us/sample - loss: 0.0359 - accuracy: 0.9826 - val_loss: 0.0500 - val_accuracy: 0.9752\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0341 - accuracy: 0.9834 - val_loss: 0.0501 - val_accuracy: 0.9750\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.0312 - accuracy: 0.9849 - val_loss: 0.0529 - val_accuracy: 0.9739\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.0312 - accuracy: 0.9849 - val_loss: 0.0502 - val_accuracy: 0.9752\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.0282 - accuracy: 0.9862 - val_loss: 0.0496 - val_accuracy: 0.9751\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.0276 - accuracy: 0.9864 - val_loss: 0.0503 - val_accuracy: 0.9745\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.0277 - accuracy: 0.9865 - val_loss: 0.0495 - val_accuracy: 0.9751\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 0.0255 - accuracy: 0.9873 - val_loss: 0.0528 - val_accuracy: 0.9741\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0245 - accuracy: 0.9879 - val_loss: 0.0476 - val_accuracy: 0.9763\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.0253 - accuracy: 0.9873 - val_loss: 0.0423 - val_accuracy: 0.9790\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.0247 - accuracy: 0.9878 - val_loss: 0.0466 - val_accuracy: 0.9769\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0237 - accuracy: 0.9885 - val_loss: 0.0435 - val_accuracy: 0.9781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25ca15a8d30>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"model = build_model(\\n    input_dim=X_train.shape[1],\\n    output_dim=y_train.shape[1],\\n    layer_nodes=[128, 64],\\n    activation_function=\\\"relu\\\",\\n    output_function=\\\"softmax\\\",\\n)\\n\\nmodel.compile(optimizer=\\\"adam\\\", loss=\\\"categorical_hinge\\\", metrics=[\\\"accuracy\\\"])\\n\\nmodel.fit(\\n    X_train,\\n    y_train,\\n    validation_data=(X_test, y_test),\\n    #     batch_size=128,\\n    epochs=20,\\n    verbose=1,\\n)\";\n",
       "                var nbb_formatted_code = \"model = build_model(\\n    input_dim=X_train.shape[1],\\n    output_dim=y_train.shape[1],\\n    layer_nodes=[128, 64],\\n    activation_function=\\\"relu\\\",\\n    output_function=\\\"softmax\\\",\\n)\\n\\nmodel.compile(optimizer=\\\"adam\\\", loss=\\\"categorical_hinge\\\", metrics=[\\\"accuracy\\\"])\\n\\nmodel.fit(\\n    X_train,\\n    y_train,\\n    validation_data=(X_test, y_test),\\n    #     batch_size=128,\\n    epochs=20,\\n    verbose=1,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = build_model(\n",
    "    input_dim=X_train.shape[1],\n",
    "    output_dim=y_train.shape[1],\n",
    "    layer_nodes=[128, 64],\n",
    "    activation_function=\"relu\",\n",
    "    output_function=\"softmax\",\n",
    ")\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_hinge\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    #     batch_size=128,\n",
    "    epochs=20,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They're all nearly identical again. Weirdly enough the first onee took longer than the second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 22us/sample - loss: 1.0110 - accuracy: 0.3233 - val_loss: 0.9848 - val_accuracy: 0.5012\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.9453 - accuracy: 0.5781 - val_loss: 0.8974 - val_accuracy: 0.6739\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.8126 - accuracy: 0.6953 - val_loss: 0.6888 - val_accuracy: 0.7457\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.5965 - accuracy: 0.7871 - val_loss: 0.4925 - val_accuracy: 0.8429\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.4401 - accuracy: 0.8532 - val_loss: 0.3682 - val_accuracy: 0.8767\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.3479 - accuracy: 0.8759 - val_loss: 0.3022 - val_accuracy: 0.8901\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.2978 - accuracy: 0.8878 - val_loss: 0.2660 - val_accuracy: 0.8967\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.2678 - accuracy: 0.8953 - val_loss: 0.2441 - val_accuracy: 0.9030\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.2474 - accuracy: 0.9004 - val_loss: 0.2282 - val_accuracy: 0.9066\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.2325 - accuracy: 0.9046 - val_loss: 0.2157 - val_accuracy: 0.9091\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.2209 - accuracy: 0.9079 - val_loss: 0.2057 - val_accuracy: 0.9130\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.2114 - accuracy: 0.9109 - val_loss: 0.1975 - val_accuracy: 0.9151\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.2036 - accuracy: 0.9133 - val_loss: 0.1915 - val_accuracy: 0.9172\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.1966 - accuracy: 0.9161 - val_loss: 0.1866 - val_accuracy: 0.9196\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.1905 - accuracy: 0.9183 - val_loss: 0.1808 - val_accuracy: 0.9219\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.1852 - accuracy: 0.9202 - val_loss: 0.1763 - val_accuracy: 0.9230\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1801 - accuracy: 0.9217 - val_loss: 0.1718 - val_accuracy: 0.9258\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 0.1755 - accuracy: 0.9238 - val_loss: 0.1688 - val_accuracy: 0.9265\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 0.1713 - accuracy: 0.9258 - val_loss: 0.1649 - val_accuracy: 0.9277\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 11us/sample - loss: 0.1674 - accuracy: 0.9269 - val_loss: 0.1616 - val_accuracy: 0.9295\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25ca149bb80>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"sgd = SGD(learning_rate=0.01)\\n\\nmodel = build_model(\\n    input_dim=X_train.shape[1],\\n    output_dim=y_train.shape[1],\\n    layer_nodes=[128, 64],\\n    activation_function=\\\"relu\\\",\\n    output_function=\\\"softmax\\\",\\n)\\n\\nmodel.compile(optimizer=sgd, loss=\\\"categorical_hinge\\\", metrics=[\\\"accuracy\\\"])\\n\\nmodel.fit(\\n    X_train,\\n    y_train,\\n    validation_data=(X_test, y_test),\\n    batch_size=128,\\n    epochs=20,\\n    verbose=1,\\n)\";\n",
       "                var nbb_formatted_code = \"sgd = SGD(learning_rate=0.01)\\n\\nmodel = build_model(\\n    input_dim=X_train.shape[1],\\n    output_dim=y_train.shape[1],\\n    layer_nodes=[128, 64],\\n    activation_function=\\\"relu\\\",\\n    output_function=\\\"softmax\\\",\\n)\\n\\nmodel.compile(optimizer=sgd, loss=\\\"categorical_hinge\\\", metrics=[\\\"accuracy\\\"])\\n\\nmodel.fit(\\n    X_train,\\n    y_train,\\n    validation_data=(X_test, y_test),\\n    batch_size=128,\\n    epochs=20,\\n    verbose=1,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sgd = SGD(learning_rate=0.01)\n",
    "\n",
    "model = build_model(\n",
    "    input_dim=X_train.shape[1],\n",
    "    output_dim=y_train.shape[1],\n",
    "    layer_nodes=[128, 64],\n",
    "    activation_function=\"relu\",\n",
    "    output_function=\"softmax\",\n",
    ")\n",
    "\n",
    "model.compile(optimizer=sgd, loss=\"categorical_hinge\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=128,\n",
    "    epochs=20,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 25us/sample - loss: 1.8033 - accuracy: 0.0974 - val_loss: 1.8036 - val_accuracy: 0.0982\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.8053 - accuracy: 0.0974 - val_loss: 1.8036 - val_accuracy: 0.0982\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.8053 - accuracy: 0.0974 - val_loss: 1.8036 - val_accuracy: 0.0982\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.8053 - accuracy: 0.0974 - val_loss: 1.8036 - val_accuracy: 0.0982\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.8053 - accuracy: 0.0974 - val_loss: 1.8036 - val_accuracy: 0.0982\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.8053 - accuracy: 0.0974 - val_loss: 1.8036 - val_accuracy: 0.0982\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.8053 - accuracy: 0.0974 - val_loss: 1.8036 - val_accuracy: 0.0982\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.8053 - accuracy: 0.0974 - val_loss: 1.8036 - val_accuracy: 0.0982\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.8053 - accuracy: 0.0974 - val_loss: 1.8036 - val_accuracy: 0.0982\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.8053 - accuracy: 0.0974 - val_loss: 1.8036 - val_accuracy: 0.0982\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.8053 - accuracy: 0.0974 - val_loss: 1.8036 - val_accuracy: 0.0982\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.8053 - accuracy: 0.0974 - val_loss: 1.8036 - val_accuracy: 0.0982\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.8053 - accuracy: 0.0974 - val_loss: 1.8036 - val_accuracy: 0.0982\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.8053 - accuracy: 0.0974 - val_loss: 1.8036 - val_accuracy: 0.0982\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.8053 - accuracy: 0.0974 - val_loss: 1.8036 - val_accuracy: 0.0982\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.8053 - accuracy: 0.0974 - val_loss: 1.8036 - val_accuracy: 0.0982\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.8053 - accuracy: 0.0974 - val_loss: 1.8036 - val_accuracy: 0.0982\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.8053 - accuracy: 0.0974 - val_loss: 1.8036 - val_accuracy: 0.0982\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.8053 - accuracy: 0.0974 - val_loss: 1.8036 - val_accuracy: 0.0982\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.8053 - accuracy: 0.0974 - val_loss: 1.8036 - val_accuracy: 0.0982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25ca176af40>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"sgd = SGD(learning_rate=100)\\n\\nmodel = build_model(\\n    input_dim=X_train.shape[1],\\n    output_dim=y_train.shape[1],\\n    layer_nodes=[128, 64],\\n    activation_function=\\\"relu\\\",\\n    output_function=\\\"softmax\\\",\\n)\\n\\nmodel.compile(optimizer=sgd, loss=\\\"categorical_hinge\\\", metrics=[\\\"accuracy\\\"])\\n\\nmodel.fit(\\n    X_train,\\n    y_train,\\n    validation_data=(X_test, y_test),\\n    batch_size=128,\\n    epochs=20,\\n    verbose=1,\\n)\";\n",
       "                var nbb_formatted_code = \"sgd = SGD(learning_rate=100)\\n\\nmodel = build_model(\\n    input_dim=X_train.shape[1],\\n    output_dim=y_train.shape[1],\\n    layer_nodes=[128, 64],\\n    activation_function=\\\"relu\\\",\\n    output_function=\\\"softmax\\\",\\n)\\n\\nmodel.compile(optimizer=sgd, loss=\\\"categorical_hinge\\\", metrics=[\\\"accuracy\\\"])\\n\\nmodel.fit(\\n    X_train,\\n    y_train,\\n    validation_data=(X_test, y_test),\\n    batch_size=128,\\n    epochs=20,\\n    verbose=1,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sgd = SGD(learning_rate=100)\n",
    "\n",
    "model = build_model(\n",
    "    input_dim=X_train.shape[1],\n",
    "    output_dim=y_train.shape[1],\n",
    "    layer_nodes=[128, 64],\n",
    "    activation_function=\"relu\",\n",
    "    output_function=\"softmax\",\n",
    ")\n",
    "\n",
    "model.compile(optimizer=sgd, loss=\"categorical_hinge\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=128,\n",
    "    epochs=20,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 2s 27us/sample - loss: 1.0787 - accuracy: 0.1179 - val_loss: 1.0809 - val_accuracy: 0.1168\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.0787 - accuracy: 0.1179 - val_loss: 1.0809 - val_accuracy: 0.1168\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.0787 - accuracy: 0.1179 - val_loss: 1.0809 - val_accuracy: 0.1168\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.0786 - accuracy: 0.1179 - val_loss: 1.0809 - val_accuracy: 0.1168\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.0786 - accuracy: 0.1179 - val_loss: 1.0809 - val_accuracy: 0.1168\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.0786 - accuracy: 0.1179 - val_loss: 1.0809 - val_accuracy: 0.1168\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.0786 - accuracy: 0.1179 - val_loss: 1.0809 - val_accuracy: 0.1168\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.0786 - accuracy: 0.1179 - val_loss: 1.0809 - val_accuracy: 0.1168\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.0786 - accuracy: 0.1179 - val_loss: 1.0809 - val_accuracy: 0.1169\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.0786 - accuracy: 0.1179 - val_loss: 1.0809 - val_accuracy: 0.1169\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.0786 - accuracy: 0.1179 - val_loss: 1.0809 - val_accuracy: 0.1169\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.0786 - accuracy: 0.1179 - val_loss: 1.0809 - val_accuracy: 0.1169\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.0786 - accuracy: 0.1179 - val_loss: 1.0809 - val_accuracy: 0.1169\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.0786 - accuracy: 0.1179 - val_loss: 1.0808 - val_accuracy: 0.1169\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.0786 - accuracy: 0.1179 - val_loss: 1.0808 - val_accuracy: 0.1170\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.0786 - accuracy: 0.1179 - val_loss: 1.0808 - val_accuracy: 0.1170\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.0786 - accuracy: 0.1179 - val_loss: 1.0808 - val_accuracy: 0.1170\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.0786 - accuracy: 0.1179 - val_loss: 1.0808 - val_accuracy: 0.1170\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 10us/sample - loss: 1.0786 - accuracy: 0.1179 - val_loss: 1.0808 - val_accuracy: 0.1170\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 9us/sample - loss: 1.0785 - accuracy: 0.1179 - val_loss: 1.0808 - val_accuracy: 0.1170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x25ca17c4af0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"sgd = SGD(learning_rate=0.0000001)\\n\\nmodel = build_model(\\n    input_dim=X_train.shape[1],\\n    output_dim=y_train.shape[1],\\n    layer_nodes=[128, 64],\\n    activation_function=\\\"relu\\\",\\n    output_function=\\\"softmax\\\",\\n)\\n\\nmodel.compile(optimizer=sgd, loss=\\\"categorical_hinge\\\", metrics=[\\\"accuracy\\\"])\\n\\nmodel.fit(\\n    X_train,\\n    y_train,\\n    validation_data=(X_test, y_test),\\n    batch_size=128,\\n    epochs=20,\\n    verbose=1,\\n)\";\n",
       "                var nbb_formatted_code = \"sgd = SGD(learning_rate=0.0000001)\\n\\nmodel = build_model(\\n    input_dim=X_train.shape[1],\\n    output_dim=y_train.shape[1],\\n    layer_nodes=[128, 64],\\n    activation_function=\\\"relu\\\",\\n    output_function=\\\"softmax\\\",\\n)\\n\\nmodel.compile(optimizer=sgd, loss=\\\"categorical_hinge\\\", metrics=[\\\"accuracy\\\"])\\n\\nmodel.fit(\\n    X_train,\\n    y_train,\\n    validation_data=(X_test, y_test),\\n    batch_size=128,\\n    epochs=20,\\n    verbose=1,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sgd = SGD(learning_rate=0.0000001)\n",
    "\n",
    "model = build_model(\n",
    "    input_dim=X_train.shape[1],\n",
    "    output_dim=y_train.shape[1],\n",
    "    layer_nodes=[128, 64],\n",
    "    activation_function=\"relu\",\n",
    "    output_function=\"softmax\",\n",
    ")\n",
    "\n",
    "model.compile(optimizer=sgd, loss=\"categorical_hinge\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    batch_size=128,\n",
    "    epochs=20,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.01 was the best learning rate. 100 is way to high and actually diverges. .0000001 fails to converge in only 20 epochs. Would probably take many thousands to reach any type of a good result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
