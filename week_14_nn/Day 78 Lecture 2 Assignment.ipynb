{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%reload_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext nb_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3vEszfzSgGvb"
   },
   "source": [
    "## Day 83 Lecture 2 Assignment\n",
    "\n",
    "In this assignment, we will learn about other optimization algorithms. We will create a neural network and try out the different optimization algorithms and compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "grVMFvpMgGvd",
    "outputId": "0a318000-5dd3-440b-c2f1-28887a23f488"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import numpy as np\\nimport pandas as pd\\nimport matplotlib\\nimport tensorflow as tf\\n\\ntf.debugging.set_log_device_placement(True)\\n\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\n\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import confusion_matrix\\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\";\n",
       "                var nbb_formatted_code = \"import numpy as np\\nimport pandas as pd\\nimport matplotlib\\nimport tensorflow as tf\\n\\ntf.debugging.set_log_device_placement(True)\\n\\nfrom tensorflow.keras.models import Sequential\\nfrom tensorflow.keras.layers import Dense\\n\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.metrics import confusion_matrix\\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "\n",
      "[[ 8.  5.]\n",
      " [20. 13.]]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"import os\\n\\ntf.compat.v1.disable_eager_execution()\\n\\nhello = tf.constant(\\\"Hello, TensorFlow!\\\")\\n\\n# sess = tf.compat.v1.Session()\\n\\nos.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"0\\\"  # You need to tell CUDA\\n# which GPU you'd like to use. if you have one GPU probably your GPU is '0'\\nwith tf.device(\\\"/device:XLA_GPU:0\\\"):\\n    a = tf.constant([1.0, 2.0, 3.0, 4.0], shape=[2, 2], name=\\\"a\\\")\\n    b = tf.constant([4.0, 3.0, 2.0, 1.0], shape=[2, 2], name=\\\"b\\\")\\n    c = tf.matmul(a, b)\\n# with tf.compat.v1.Session() as sess:\\n#     print(sess.run(c))\\n\\nsess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\\n# Runs the op.\\nprint(sess.run(c))\";\n",
       "                var nbb_formatted_code = \"import os\\n\\ntf.compat.v1.disable_eager_execution()\\n\\nhello = tf.constant(\\\"Hello, TensorFlow!\\\")\\n\\n# sess = tf.compat.v1.Session()\\n\\nos.environ[\\\"CUDA_VISIBLE_DEVICES\\\"] = \\\"0\\\"  # You need to tell CUDA\\n# which GPU you'd like to use. if you have one GPU probably your GPU is '0'\\nwith tf.device(\\\"/device:XLA_GPU:0\\\"):\\n    a = tf.constant([1.0, 2.0, 3.0, 4.0], shape=[2, 2], name=\\\"a\\\")\\n    b = tf.constant([4.0, 3.0, 2.0, 1.0], shape=[2, 2], name=\\\"b\\\")\\n    c = tf.matmul(a, b)\\n# with tf.compat.v1.Session() as sess:\\n#     print(sess.run(c))\\n\\nsess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\\n# Runs the op.\\nprint(sess.run(c))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "hello = tf.constant(\"Hello, TensorFlow!\")\n",
    "\n",
    "# sess = tf.compat.v1.Session()\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # You need to tell CUDA\n",
    "# which GPU you'd like to use. if you have one GPU probably your GPU is '0'\n",
    "with tf.device(\"/device:XLA_GPU:0\"):\n",
    "    a = tf.constant([1.0, 2.0, 3.0, 4.0], shape=[2, 2], name=\"a\")\n",
    "    b = tf.constant([4.0, 3.0, 2.0, 1.0], shape=[2, 2], name=\"b\")\n",
    "    c = tf.matmul(a, b)\n",
    "# with tf.compat.v1.Session() as sess:\n",
    "#     print(sess.run(c))\n",
    "\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
    "# Runs the op.\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"def build_model(\\n    input_dim,\\n    output_dim=1,\\n    layer_nodes=[64, 32, 32],\\n    activation_function=\\\"relu\\\",\\n    output_function=\\\"sigmoid\\\",\\n):\\n    model = Sequential()\\n    model.add(\\n        Dense(layer_nodes[0], input_dim=input_dim, activation=activation_function)\\n    )\\n    for i in range(1, len(layer_nodes)):\\n        model.add(Dense(layer_nodes[i], activation=activation_function))\\n\\n    model.add(Dense(output_dim, activation=output_function))\\n\\n    return model\";\n",
       "                var nbb_formatted_code = \"def build_model(\\n    input_dim,\\n    output_dim=1,\\n    layer_nodes=[64, 32, 32],\\n    activation_function=\\\"relu\\\",\\n    output_function=\\\"sigmoid\\\",\\n):\\n    model = Sequential()\\n    model.add(\\n        Dense(layer_nodes[0], input_dim=input_dim, activation=activation_function)\\n    )\\n    for i in range(1, len(layer_nodes)):\\n        model.add(Dense(layer_nodes[i], activation=activation_function))\\n\\n    model.add(Dense(output_dim, activation=output_function))\\n\\n    return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_model(\n",
    "    input_dim,\n",
    "    output_dim=1,\n",
    "    layer_nodes=[64, 32, 32],\n",
    "    activation_function=\"relu\",\n",
    "    output_function=\"sigmoid\",\n",
    "):\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Dense(layer_nodes[0], input_dim=input_dim, activation=activation_function)\n",
    "    )\n",
    "    for i in range(1, len(layer_nodes)):\n",
    "        model.add(Dense(layer_nodes[i], activation=activation_function))\n",
    "\n",
    "    model.add(Dense(output_dim, activation=output_function))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uJfwGXExgGvf"
   },
   "source": [
    "In this assignment, we will be using the cancer data that we have worked with in previous lessons. The pre-processed data is loaded below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "itA0U381gGvg"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"cancer = pd.read_csv(\\\"data/cancer_processed.csv\\\")\";\n",
       "                var nbb_formatted_code = \"cancer = pd.read_csv(\\\"data/cancer_processed.csv\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cancer = pd.read_csv(\"data/cancer_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ocNzndc-gGvi",
    "outputId": "247913e1-774f-4e7c-8bdf-5f4bd201edfe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   fractal_dimension_mean diagnosis  \n",
       "0                 0.07871         M  \n",
       "1                 0.05667         M  \n",
       "2                 0.05999         M  \n",
       "3                 0.09744         M  \n",
       "4                 0.05883         M  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"cancer.head()\";\n",
       "                var nbb_formatted_code = \"cancer.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cancer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UMyeFkQTgGvm"
   },
   "source": [
    "As you may recall, diagnosis is the target variable. One hot encode the diagnosis column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2tCQR6LjgGvn"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"# Answer below:\\ncancer['target'] = (cancer['diagnosis']=='M').astype(int)\";\n",
       "                var nbb_formatted_code = \"# Answer below:\\ncancer[\\\"target\\\"] = (cancer[\\\"diagnosis\\\"] == \\\"M\\\").astype(int)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Answer below:\n",
    "cancer['target'] = (cancer['diagnosis']=='M').astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LcJDxAb7gGvp"
   },
   "source": [
    "Split the data into train and test with 20% of the data in test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o9DgU09lgGvq"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"# Answer below\\nX = cancer.drop(['diagnosis','target'],1)\\ny = cancer[['target']]\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=34)\";\n",
       "                var nbb_formatted_code = \"# Answer below\\nX = cancer.drop([\\\"diagnosis\\\", \\\"target\\\"], 1)\\ny = cancer[[\\\"target\\\"]]\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, y, test_size=0.2, random_state=34\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Answer below\n",
    "X = cancer.drop(['diagnosis','target'],1)\n",
    "y = cancer[['target']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=34)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9eghtF43gGvk"
   },
   "source": [
    "Scale all other variables using the standard scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e7cjZatEgGvk"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"# Answer below:\\nscaler = StandardScaler()\\nX_train = scaler.fit_transform(X_train)\\nX_test = scaler.transform(X_test)\";\n",
       "                var nbb_formatted_code = \"# Answer below:\\nscaler = StandardScaler()\\nX_train = scaler.fit_transform(X_train)\\nX_test = scaler.transform(X_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Answer below:\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"X.shape[1]\";\n",
       "                var nbb_formatted_code = \"X.shape[1]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GTOKHMqrgGvr"
   },
   "source": [
    "Generate a sequential model consisting of 5 layers. The layers should be of size 128, 64, 32, 32, 1. Use the appropriate activation for the output layer based on the type of prediction algorithm we are producing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"from tensorflow.keras.optimizers import SGD, RMSprop, Adam\";\n",
       "                var nbb_formatted_code = \"from tensorflow.keras.optimizers import SGD, RMSprop, Adam\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SuLbt7X2gGvs"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"# Answer below\";\n",
       "                var nbb_formatted_code = \"# Answer below\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Answer below\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LLyq5KXtgGvt"
   },
   "source": [
    "Initialize a SGD optimizer with learning rate 0.05 and momentum 0.9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jlNXLxoUgGvu"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"# Answer below:\";\n",
       "                var nbb_formatted_code = \"# Answer below:\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Answer below:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X-O0YHk_gGvv"
   },
   "source": [
    "Compile and fit the model using the appropriate loss function and metric and use the optimizers defined above.\n",
    "\n",
    "batch size = 100, epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SD9IZdHMgGvw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 114 samples\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "\n",
      "Epoch 1/200\n",
      "100/455 [=====>........................] - ETA: 0s - loss: 0.6912 - accuracy: 0.5400WARNING:tensorflow:From C:\\Users\\b1t\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py:2048: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "455/455 [==============================] - 3s 6ms/sample - loss: 0.6656 - accuracy: 0.6505 - val_loss: 0.5436 - val_accuracy: 0.8860\n",
      "Epoch 2/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.4619 - accuracy: 0.9033 - val_loss: 0.2801 - val_accuracy: 0.9386\n",
      "Epoch 3/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.2331 - accuracy: 0.9385 - val_loss: 0.1424 - val_accuracy: 0.9298\n",
      "Epoch 4/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.1712 - accuracy: 0.9363 - val_loss: 0.1259 - val_accuracy: 0.9561\n",
      "Epoch 5/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.1621 - accuracy: 0.9363 - val_loss: 0.1190 - val_accuracy: 0.9561\n",
      "Epoch 6/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 0.1535 - accuracy: 0.9451 - val_loss: 0.1107 - val_accuracy: 0.9474\n",
      "Epoch 7/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.1382 - accuracy: 0.9429 - val_loss: 0.0989 - val_accuracy: 0.9474\n",
      "Epoch 8/200\n",
      "455/455 [==============================] - 0s 20us/sample - loss: 0.1244 - accuracy: 0.9451 - val_loss: 0.1097 - val_accuracy: 0.9561\n",
      "Epoch 9/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 0.1208 - accuracy: 0.9495 - val_loss: 0.0937 - val_accuracy: 0.9737\n",
      "Epoch 10/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.1143 - accuracy: 0.9538 - val_loss: 0.0811 - val_accuracy: 0.9649\n",
      "Epoch 11/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.1131 - accuracy: 0.9560 - val_loss: 0.0863 - val_accuracy: 0.9825\n",
      "Epoch 12/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 0.1043 - accuracy: 0.9626 - val_loss: 0.0871 - val_accuracy: 0.9649\n",
      "Epoch 13/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.1031 - accuracy: 0.9626 - val_loss: 0.0756 - val_accuracy: 0.9737\n",
      "Epoch 14/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 0.0989 - accuracy: 0.9604 - val_loss: 0.0891 - val_accuracy: 0.9912\n",
      "Epoch 15/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0967 - accuracy: 0.9538 - val_loss: 0.0854 - val_accuracy: 0.9825\n",
      "Epoch 16/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0920 - accuracy: 0.9670 - val_loss: 0.0808 - val_accuracy: 0.9737\n",
      "Epoch 17/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0888 - accuracy: 0.9648 - val_loss: 0.0741 - val_accuracy: 0.9825\n",
      "Epoch 18/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 0.0849 - accuracy: 0.9670 - val_loss: 0.0779 - val_accuracy: 0.9737\n",
      "Epoch 19/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 0.0823 - accuracy: 0.9692 - val_loss: 0.0885 - val_accuracy: 0.9825\n",
      "Epoch 20/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 0.0805 - accuracy: 0.9692 - val_loss: 0.0757 - val_accuracy: 0.9825\n",
      "Epoch 21/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 0.0795 - accuracy: 0.9692 - val_loss: 0.0802 - val_accuracy: 0.9737\n",
      "Epoch 22/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 0.0759 - accuracy: 0.9714 - val_loss: 0.0817 - val_accuracy: 0.9912\n",
      "Epoch 23/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 0.0716 - accuracy: 0.9736 - val_loss: 0.0807 - val_accuracy: 0.9912\n",
      "Epoch 24/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0707 - accuracy: 0.9692 - val_loss: 0.0930 - val_accuracy: 0.9825\n",
      "Epoch 25/200\n",
      "455/455 [==============================] - 0s 20us/sample - loss: 0.0685 - accuracy: 0.9758 - val_loss: 0.0785 - val_accuracy: 0.9825\n",
      "Epoch 26/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0676 - accuracy: 0.9780 - val_loss: 0.0676 - val_accuracy: 0.9912\n",
      "Epoch 27/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 0.0642 - accuracy: 0.9780 - val_loss: 0.0864 - val_accuracy: 0.9825\n",
      "Epoch 28/200\n",
      "455/455 [==============================] - 0s 22us/sample - loss: 0.0606 - accuracy: 0.9824 - val_loss: 0.0828 - val_accuracy: 0.9912\n",
      "Epoch 29/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0589 - accuracy: 0.9802 - val_loss: 0.0632 - val_accuracy: 0.9912\n",
      "Epoch 30/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0575 - accuracy: 0.9802 - val_loss: 0.0692 - val_accuracy: 0.9825\n",
      "Epoch 31/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0557 - accuracy: 0.9780 - val_loss: 0.0805 - val_accuracy: 0.9737\n",
      "Epoch 32/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0525 - accuracy: 0.9802 - val_loss: 0.0649 - val_accuracy: 0.9737\n",
      "Epoch 33/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0528 - accuracy: 0.9824 - val_loss: 0.0631 - val_accuracy: 0.9912\n",
      "Epoch 34/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 0.0510 - accuracy: 0.9758 - val_loss: 0.0865 - val_accuracy: 0.9825\n",
      "Epoch 35/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0520 - accuracy: 0.9780 - val_loss: 0.0778 - val_accuracy: 0.9825\n",
      "Epoch 36/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0661 - accuracy: 0.9714 - val_loss: 0.0554 - val_accuracy: 0.9825\n",
      "Epoch 37/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 0.0579 - accuracy: 0.9714 - val_loss: 0.0849 - val_accuracy: 0.9825\n",
      "Epoch 38/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0537 - accuracy: 0.9758 - val_loss: 0.0820 - val_accuracy: 0.9825\n",
      "Epoch 39/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 0.0399 - accuracy: 0.9890 - val_loss: 0.0562 - val_accuracy: 0.9825\n",
      "Epoch 40/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0500 - accuracy: 0.9780 - val_loss: 0.0958 - val_accuracy: 0.9561\n",
      "Epoch 41/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 0.0563 - accuracy: 0.9736 - val_loss: 0.0719 - val_accuracy: 0.9825\n",
      "Epoch 42/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 0.0887 - accuracy: 0.9692 - val_loss: 0.0504 - val_accuracy: 0.9825\n",
      "Epoch 43/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0549 - accuracy: 0.9714 - val_loss: 0.0889 - val_accuracy: 0.9649\n",
      "Epoch 44/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0770 - accuracy: 0.9670 - val_loss: 0.0624 - val_accuracy: 0.9737\n",
      "Epoch 45/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0554 - accuracy: 0.9824 - val_loss: 0.1421 - val_accuracy: 0.9474\n",
      "Epoch 46/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0520 - accuracy: 0.9846 - val_loss: 0.0417 - val_accuracy: 0.9912\n",
      "Epoch 47/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0434 - accuracy: 0.9846 - val_loss: 0.0711 - val_accuracy: 0.9649\n",
      "Epoch 48/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0417 - accuracy: 0.9868 - val_loss: 0.0691 - val_accuracy: 0.9649\n",
      "Epoch 49/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0374 - accuracy: 0.9846 - val_loss: 0.0577 - val_accuracy: 0.9825\n",
      "Epoch 50/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0328 - accuracy: 0.9868 - val_loss: 0.0924 - val_accuracy: 0.9561\n",
      "Epoch 51/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0300 - accuracy: 0.9912 - val_loss: 0.0620 - val_accuracy: 0.9737\n",
      "Epoch 52/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0278 - accuracy: 0.9912 - val_loss: 0.0942 - val_accuracy: 0.9561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0281 - accuracy: 0.9912 - val_loss: 0.0500 - val_accuracy: 0.9825\n",
      "Epoch 54/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0435 - accuracy: 0.9802 - val_loss: 0.0809 - val_accuracy: 0.9561\n",
      "Epoch 55/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0411 - accuracy: 0.9824 - val_loss: 0.0608 - val_accuracy: 0.9737\n",
      "Epoch 56/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0433 - accuracy: 0.9824 - val_loss: 0.0969 - val_accuracy: 0.9737\n",
      "Epoch 57/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0416 - accuracy: 0.9890 - val_loss: 0.0434 - val_accuracy: 0.9912\n",
      "Epoch 58/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0567 - accuracy: 0.9824 - val_loss: 0.0792 - val_accuracy: 0.9737\n",
      "Epoch 59/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0626 - accuracy: 0.9780 - val_loss: 0.1874 - val_accuracy: 0.9561\n",
      "Epoch 60/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0301 - accuracy: 0.9868 - val_loss: 0.1366 - val_accuracy: 0.9649\n",
      "Epoch 61/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0362 - accuracy: 0.9868 - val_loss: 0.1415 - val_accuracy: 0.9737\n",
      "Epoch 62/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0258 - accuracy: 0.9912 - val_loss: 0.0702 - val_accuracy: 0.9825\n",
      "Epoch 63/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0260 - accuracy: 0.9868 - val_loss: 0.0363 - val_accuracy: 0.9737\n",
      "Epoch 64/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0216 - accuracy: 0.9934 - val_loss: 0.0527 - val_accuracy: 0.9825\n",
      "Epoch 65/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0194 - accuracy: 0.9934 - val_loss: 0.0450 - val_accuracy: 0.9737\n",
      "Epoch 66/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0171 - accuracy: 0.9956 - val_loss: 0.0466 - val_accuracy: 0.9737\n",
      "Epoch 67/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0154 - accuracy: 0.9934 - val_loss: 0.0447 - val_accuracy: 0.9737\n",
      "Epoch 68/200\n",
      "455/455 [==============================] - 0s 20us/sample - loss: 0.0168 - accuracy: 0.9956 - val_loss: 0.0486 - val_accuracy: 0.9737\n",
      "Epoch 69/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0222 - accuracy: 0.9956 - val_loss: 0.0501 - val_accuracy: 0.9649\n",
      "Epoch 70/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0241 - accuracy: 0.9912 - val_loss: 0.0502 - val_accuracy: 0.9737\n",
      "Epoch 71/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0259 - accuracy: 0.9868 - val_loss: 0.0395 - val_accuracy: 0.9825\n",
      "Epoch 72/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0336 - accuracy: 0.9890 - val_loss: 0.0534 - val_accuracy: 0.9825\n",
      "Epoch 73/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0194 - accuracy: 0.9912 - val_loss: 0.0445 - val_accuracy: 0.9737\n",
      "Epoch 74/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0646 - val_accuracy: 0.9649\n",
      "Epoch 75/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0148 - accuracy: 0.9978 - val_loss: 0.0379 - val_accuracy: 0.9825\n",
      "Epoch 76/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 0.0133 - accuracy: 0.9956 - val_loss: 0.0435 - val_accuracy: 0.9825\n",
      "Epoch 77/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0111 - accuracy: 0.9956 - val_loss: 0.0573 - val_accuracy: 0.9737\n",
      "Epoch 78/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 0.0090 - accuracy: 1.0000 - val_loss: 0.0389 - val_accuracy: 0.9825\n",
      "Epoch 79/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0101 - accuracy: 0.9956 - val_loss: 0.0651 - val_accuracy: 0.9649\n",
      "Epoch 80/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.9825\n",
      "Epoch 81/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0142 - accuracy: 0.9956 - val_loss: 0.0550 - val_accuracy: 0.9825\n",
      "Epoch 82/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.0588 - val_accuracy: 0.9737\n",
      "Epoch 83/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0079 - accuracy: 0.9978 - val_loss: 0.0447 - val_accuracy: 0.9737\n",
      "Epoch 84/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0106 - accuracy: 0.9956 - val_loss: 0.0657 - val_accuracy: 0.9737\n",
      "Epoch 85/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.0510 - val_accuracy: 0.9825\n",
      "Epoch 86/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0074 - accuracy: 0.9956 - val_loss: 0.0545 - val_accuracy: 0.9825\n",
      "Epoch 87/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 0.0059 - accuracy: 0.9978 - val_loss: 0.0560 - val_accuracy: 0.9825\n",
      "Epoch 88/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0154 - accuracy: 0.9978 - val_loss: 0.0533 - val_accuracy: 0.9825\n",
      "Epoch 89/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0105 - accuracy: 0.9978 - val_loss: 0.0628 - val_accuracy: 0.9737\n",
      "Epoch 90/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0163 - accuracy: 0.9912 - val_loss: 0.0517 - val_accuracy: 0.9825\n",
      "Epoch 91/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0056 - accuracy: 0.9978 - val_loss: 0.0580 - val_accuracy: 0.9737\n",
      "Epoch 92/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0082 - accuracy: 0.9978 - val_loss: 0.0508 - val_accuracy: 0.9737\n",
      "Epoch 93/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0098 - accuracy: 0.9956 - val_loss: 0.0619 - val_accuracy: 0.9737\n",
      "Epoch 94/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0076 - accuracy: 0.9956 - val_loss: 0.0463 - val_accuracy: 0.9825\n",
      "Epoch 95/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0134 - accuracy: 0.9956 - val_loss: 0.0756 - val_accuracy: 0.9649\n",
      "Epoch 96/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0647 - val_accuracy: 0.9825\n",
      "Epoch 97/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 0.0115 - accuracy: 0.9978 - val_loss: 0.0579 - val_accuracy: 0.9825\n",
      "Epoch 98/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0054 - accuracy: 1.0000 - val_loss: 0.0676 - val_accuracy: 0.9737\n",
      "Epoch 99/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0079 - accuracy: 0.9956 - val_loss: 0.0496 - val_accuracy: 0.9737\n",
      "Epoch 100/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.0597 - val_accuracy: 0.9825\n",
      "Epoch 101/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.0683 - val_accuracy: 0.9737\n",
      "Epoch 102/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0643 - val_accuracy: 0.9737\n",
      "Epoch 103/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0626 - val_accuracy: 0.9737\n",
      "Epoch 104/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0654 - val_accuracy: 0.9649\n",
      "Epoch 105/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.0630 - val_accuracy: 0.9737\n",
      "Epoch 106/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0637 - val_accuracy: 0.9825\n",
      "Epoch 107/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0038 - accuracy: 0.9978 - val_loss: 0.0663 - val_accuracy: 0.9825\n",
      "Epoch 108/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 0.9649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0616 - val_accuracy: 0.9737\n",
      "Epoch 110/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0647 - val_accuracy: 0.9737\n",
      "Epoch 111/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0766 - val_accuracy: 0.9649\n",
      "Epoch 112/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0623 - val_accuracy: 0.9737\n",
      "Epoch 113/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0686 - val_accuracy: 0.9737\n",
      "Epoch 114/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0058 - accuracy: 0.9978 - val_loss: 0.0685 - val_accuracy: 0.9825\n",
      "Epoch 115/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0685 - val_accuracy: 0.9825\n",
      "Epoch 116/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0805 - val_accuracy: 0.9737\n",
      "Epoch 117/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.0688 - val_accuracy: 0.9737\n",
      "Epoch 118/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0646 - val_accuracy: 0.9737\n",
      "Epoch 119/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.0706 - val_accuracy: 0.9737\n",
      "Epoch 120/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0758 - val_accuracy: 0.9737\n",
      "Epoch 121/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0706 - val_accuracy: 0.9737\n",
      "Epoch 122/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0035 - accuracy: 0.9978 - val_loss: 0.0742 - val_accuracy: 0.9737\n",
      "Epoch 123/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 0.0152 - accuracy: 0.9978 - val_loss: 0.0702 - val_accuracy: 0.9737\n",
      "Epoch 124/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0121 - accuracy: 0.9956 - val_loss: 0.0740 - val_accuracy: 0.9825\n",
      "Epoch 125/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0206 - accuracy: 0.9934 - val_loss: 0.1393 - val_accuracy: 0.9561\n",
      "Epoch 126/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0410 - accuracy: 0.9890 - val_loss: 0.1026 - val_accuracy: 0.9737\n",
      "Epoch 127/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0288 - accuracy: 0.9912 - val_loss: 0.0879 - val_accuracy: 0.9737\n",
      "Epoch 128/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 0.0060 - accuracy: 0.9978 - val_loss: 0.0782 - val_accuracy: 0.9737\n",
      "Epoch 129/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 0.0213 - accuracy: 0.9934 - val_loss: 0.0872 - val_accuracy: 0.9737\n",
      "Epoch 130/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0742 - accuracy: 0.9780 - val_loss: 0.1164 - val_accuracy: 0.9737\n",
      "Epoch 131/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.1198 - accuracy: 0.9714 - val_loss: 0.2231 - val_accuracy: 0.9737\n",
      "Epoch 132/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 0.0703 - accuracy: 0.9846 - val_loss: 0.2347 - val_accuracy: 0.9298\n",
      "Epoch 133/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.1226 - accuracy: 0.9670 - val_loss: 0.2237 - val_accuracy: 0.9737\n",
      "Epoch 134/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0689 - accuracy: 0.9714 - val_loss: 0.1654 - val_accuracy: 0.9649\n",
      "Epoch 135/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0523 - accuracy: 0.9780 - val_loss: 0.1739 - val_accuracy: 0.9474\n",
      "Epoch 136/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0392 - accuracy: 0.9868 - val_loss: 0.1624 - val_accuracy: 0.9737\n",
      "Epoch 137/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0322 - accuracy: 0.9890 - val_loss: 0.1732 - val_accuracy: 0.9737\n",
      "Epoch 138/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0199 - accuracy: 0.9956 - val_loss: 0.1764 - val_accuracy: 0.9737\n",
      "Epoch 139/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0214 - accuracy: 0.9934 - val_loss: 0.1371 - val_accuracy: 0.9737\n",
      "Epoch 140/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0159 - accuracy: 0.9956 - val_loss: 0.1563 - val_accuracy: 0.9737\n",
      "Epoch 141/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0143 - accuracy: 0.9934 - val_loss: 0.1987 - val_accuracy: 0.9649\n",
      "Epoch 142/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 0.0114 - accuracy: 0.9978 - val_loss: 0.1791 - val_accuracy: 0.9737\n",
      "Epoch 143/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 0.0094 - accuracy: 0.9956 - val_loss: 0.1232 - val_accuracy: 0.9737\n",
      "Epoch 144/200\n",
      "455/455 [==============================] - 0s 20us/sample - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.1188 - val_accuracy: 0.9737\n",
      "Epoch 145/200\n",
      "455/455 [==============================] - 0s 20us/sample - loss: 0.0064 - accuracy: 1.0000 - val_loss: 0.1192 - val_accuracy: 0.9737\n",
      "Epoch 146/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0062 - accuracy: 1.0000 - val_loss: 0.1041 - val_accuracy: 0.9737\n",
      "Epoch 147/200\n",
      "455/455 [==============================] - 0s 20us/sample - loss: 0.0059 - accuracy: 1.0000 - val_loss: 0.1047 - val_accuracy: 0.9737\n",
      "Epoch 148/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.1049 - val_accuracy: 0.9737\n",
      "Epoch 149/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0052 - accuracy: 0.9978 - val_loss: 0.1071 - val_accuracy: 0.9737\n",
      "Epoch 150/200\n",
      "455/455 [==============================] - 0s 20us/sample - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.1127 - val_accuracy: 0.9737\n",
      "Epoch 151/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.1213 - val_accuracy: 0.9737\n",
      "Epoch 152/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1235 - val_accuracy: 0.9737\n",
      "Epoch 153/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.1279 - val_accuracy: 0.9737\n",
      "Epoch 154/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.1338 - val_accuracy: 0.9737\n",
      "Epoch 155/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1354 - val_accuracy: 0.9737\n",
      "Epoch 156/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9737\n",
      "Epoch 157/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1415 - val_accuracy: 0.9737\n",
      "Epoch 158/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.1430 - val_accuracy: 0.9737\n",
      "Epoch 159/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.1367 - val_accuracy: 0.9737\n",
      "Epoch 160/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.1367 - val_accuracy: 0.9737\n",
      "Epoch 161/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.1370 - val_accuracy: 0.9737\n",
      "Epoch 162/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9737\n",
      "Epoch 163/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.1410 - val_accuracy: 0.9737\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.1432 - val_accuracy: 0.9737\n",
      "Epoch 165/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1418 - val_accuracy: 0.9737\n",
      "Epoch 166/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.1396 - val_accuracy: 0.9737\n",
      "Epoch 167/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.1395 - val_accuracy: 0.9737\n",
      "Epoch 168/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.1382 - val_accuracy: 0.9737\n",
      "Epoch 169/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1371 - val_accuracy: 0.9737\n",
      "Epoch 170/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1366 - val_accuracy: 0.9737\n",
      "Epoch 171/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.1351 - val_accuracy: 0.9737\n",
      "Epoch 172/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1355 - val_accuracy: 0.9737\n",
      "Epoch 173/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1376 - val_accuracy: 0.9737\n",
      "Epoch 174/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1387 - val_accuracy: 0.9737\n",
      "Epoch 175/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1387 - val_accuracy: 0.9737\n",
      "Epoch 176/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1390 - val_accuracy: 0.9737\n",
      "Epoch 177/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1393 - val_accuracy: 0.9737\n",
      "Epoch 178/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.1395 - val_accuracy: 0.9737\n",
      "Epoch 179/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1387 - val_accuracy: 0.9737\n",
      "Epoch 180/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.6031e-04 - accuracy: 1.0000 - val_loss: 0.1389 - val_accuracy: 0.9737\n",
      "Epoch 181/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.7614e-04 - accuracy: 1.0000 - val_loss: 0.1383 - val_accuracy: 0.9737\n",
      "Epoch 182/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.5584e-04 - accuracy: 1.0000 - val_loss: 0.1393 - val_accuracy: 0.9737\n",
      "Epoch 183/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.0848e-04 - accuracy: 1.0000 - val_loss: 0.1401 - val_accuracy: 0.9737\n",
      "Epoch 184/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.0494e-04 - accuracy: 1.0000 - val_loss: 0.1403 - val_accuracy: 0.9737\n",
      "Epoch 185/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.2326e-04 - accuracy: 1.0000 - val_loss: 0.1406 - val_accuracy: 0.9737\n",
      "Epoch 186/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 8.9652e-04 - accuracy: 1.0000 - val_loss: 0.1415 - val_accuracy: 0.9737\n",
      "Epoch 187/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 8.7905e-04 - accuracy: 1.0000 - val_loss: 0.1422 - val_accuracy: 0.9737\n",
      "Epoch 188/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 9.4812e-04 - accuracy: 1.0000 - val_loss: 0.1423 - val_accuracy: 0.9737\n",
      "Epoch 189/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 8.9652e-04 - accuracy: 1.0000 - val_loss: 0.1424 - val_accuracy: 0.9737\n",
      "Epoch 190/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 8.8139e-04 - accuracy: 1.0000 - val_loss: 0.1422 - val_accuracy: 0.9737\n",
      "Epoch 191/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 8.9766e-04 - accuracy: 1.0000 - val_loss: 0.1408 - val_accuracy: 0.9737\n",
      "Epoch 192/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 9.8702e-04 - accuracy: 1.0000 - val_loss: 0.1403 - val_accuracy: 0.9737\n",
      "Epoch 193/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 7.7563e-04 - accuracy: 1.0000 - val_loss: 0.1417 - val_accuracy: 0.9737\n",
      "Epoch 194/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 8.1789e-04 - accuracy: 1.0000 - val_loss: 0.1431 - val_accuracy: 0.9737\n",
      "Epoch 195/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 6.7379e-04 - accuracy: 1.0000 - val_loss: 0.1422 - val_accuracy: 0.9737\n",
      "Epoch 196/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 7.4090e-04 - accuracy: 1.0000 - val_loss: 0.1421 - val_accuracy: 0.9737\n",
      "Epoch 197/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 7.4163e-04 - accuracy: 1.0000 - val_loss: 0.1422 - val_accuracy: 0.9737\n",
      "Epoch 198/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 7.2369e-04 - accuracy: 1.0000 - val_loss: 0.1422 - val_accuracy: 0.9737\n",
      "Epoch 199/200\n",
      "455/455 [==============================] - 0s 29us/sample - loss: 6.8827e-04 - accuracy: 1.0000 - val_loss: 0.1429 - val_accuracy: 0.9737\n",
      "Epoch 200/200\n",
      "455/455 [==============================] - 0s 20us/sample - loss: 6.8739e-04 - accuracy: 1.0000 - val_loss: 0.1450 - val_accuracy: 0.9737\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"# Answer below:\\n# with tf.device(\\\"/device:XLA_GPU:0\\\"):\\nsgd = SGD(learning_rate=0.05, momentum=0.9)\\nmodel = build_model(\\n    X.shape[1],\\n    output_dim=y.shape[1],\\n    layer_nodes=[128, 64, 32, 32],\\n    activation_function=\\\"relu\\\",\\n    output_function=\\\"sigmoid\\\",\\n)\\nmodel.compile(loss=\\\"binary_crossentropy\\\", optimizer=sgd, metrics=[\\\"accuracy\\\"])\\nhistory = model.fit(\\n    X_train, y_train, validation_data=(X_test, y_test), batch_size=100, epochs=200\\n)\";\n",
       "                var nbb_formatted_code = \"# Answer below:\\n# with tf.device(\\\"/device:XLA_GPU:0\\\"):\\nsgd = SGD(learning_rate=0.05, momentum=0.9)\\nmodel = build_model(\\n    X.shape[1],\\n    output_dim=y.shape[1],\\n    layer_nodes=[128, 64, 32, 32],\\n    activation_function=\\\"relu\\\",\\n    output_function=\\\"sigmoid\\\",\\n)\\nmodel.compile(loss=\\\"binary_crossentropy\\\", optimizer=sgd, metrics=[\\\"accuracy\\\"])\\nhistory = model.fit(\\n    X_train, y_train, validation_data=(X_test, y_test), batch_size=100, epochs=200\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Answer below:\n",
    "# with tf.device(\"/device:XLA_GPU:0\"):\n",
    "sgd = SGD(learning_rate=0.05, momentum=0.9)\n",
    "model = build_model(\n",
    "    X.shape[1],\n",
    "    output_dim=y.shape[1],\n",
    "    layer_nodes=[128, 64, 32, 32],\n",
    "    activation_function=\"relu\",\n",
    "    output_function=\"sigmoid\",\n",
    ")\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=sgd, metrics=[\"accuracy\"])\n",
    "history = model.fit(\n",
    "    X_train, y_train, validation_data=(X_test, y_test), batch_size=100, epochs=200\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"pd.DataFrame(history.history)[[\\\"accuracy\\\", \\\"val_accuracy\\\"]].plot()\";\n",
       "                var nbb_formatted_code = \"pd.DataFrame(history.history)[[\\\"accuracy\\\", \\\"val_accuracy\\\"]].plot()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)[[\"accuracy\", \"val_accuracy\"]].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9sRBwGzsgGvx"
   },
   "source": [
    "Define the RMSprop optimizer with a learning rate of 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "odyJo-kugGvy"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"# Answer below:\\nrms = RMSprop(learning_rate=0.05)\";\n",
       "                var nbb_formatted_code = \"# Answer below:\\nrms = RMSprop(learning_rate=0.05)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Answer below:\n",
    "rms = RMSprop(learning_rate=0.05)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o7GaEJGugGvz"
   },
   "source": [
    "Compile and fit the model using the optimizer defined above. What do you notice about the accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "477zsxjvgGv0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 114 samples\n",
      "Epoch 1/200\n",
      "455/455 [==============================] - 6s 13ms/sample - loss: 7.5331 - accuracy: 0.3890 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 2/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 3/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 4/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 5/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 6/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 7/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 8/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 9/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 10/200\n",
      "455/455 [==============================] - 0s 20us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 11/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 12/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 13/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 14/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 15/200\n",
      "455/455 [==============================] - 0s 20us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 16/200\n",
      "455/455 [==============================] - 0s 22us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 17/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 18/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 19/200\n",
      "455/455 [==============================] - 0s 20us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 20/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 21/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 22/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 23/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 24/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 25/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 26/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 27/200\n",
      "455/455 [==============================] - 0s 17us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 28/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 29/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 30/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 31/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 32/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 33/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 34/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 35/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 36/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 37/200\n",
      "455/455 [==============================] - 0s 20us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 38/200\n",
      "455/455 [==============================] - 0s 16us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 39/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 40/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 41/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 42/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 43/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 44/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 45/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 46/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 47/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 48/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 49/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 50/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 51/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 52/200\n",
      "455/455 [==============================] - 0s 22us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 53/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 54/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 55/200\n",
      "455/455 [==============================] - 0s 20us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 56/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 57/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 58/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 59/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 60/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 61/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 62/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 63/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 64/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 65/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 66/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 67/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 68/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 69/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 70/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 71/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 72/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 73/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 74/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 75/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 76/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 77/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 78/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 79/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 80/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 81/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 82/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 83/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 84/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 85/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 86/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 87/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 88/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 89/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 90/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 91/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 92/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 93/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 94/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 95/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 96/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 97/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 98/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 99/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 100/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 101/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 102/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 103/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 104/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 105/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 106/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 107/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 108/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 109/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 110/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 111/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 0s 11us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 112/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 113/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 114/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 115/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 116/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 117/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 118/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 119/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 120/200\n",
      "455/455 [==============================] - 0s 20us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 121/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 122/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 123/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 124/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 125/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 126/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 127/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 128/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 129/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 130/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 131/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 132/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 133/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 134/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 135/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 136/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 137/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 138/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 139/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 140/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 141/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 142/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 143/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 144/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 145/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 146/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 147/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 148/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 149/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 150/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 151/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 152/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 153/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 154/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 155/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 156/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 157/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 158/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 159/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 160/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 161/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 162/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 163/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 164/200\n",
      "455/455 [==============================] - 0s 24us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 165/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 167/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 168/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 169/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 170/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 171/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 172/200\n",
      "455/455 [==============================] - 0s 20us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 173/200\n",
      "455/455 [==============================] - 0s 20us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 174/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 175/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 176/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 177/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 178/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 179/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 180/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 181/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 182/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 183/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 184/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 185/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 186/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 187/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 188/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 189/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 190/200\n",
      "455/455 [==============================] - 0s 20us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 191/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 192/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 193/200\n",
      "455/455 [==============================] - 0s 18us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 194/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 195/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 196/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 197/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 198/200\n",
      "455/455 [==============================] - 0s 15us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 199/200\n",
      "455/455 [==============================] - 0s 11us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n",
      "Epoch 200/200\n",
      "455/455 [==============================] - 0s 13us/sample - loss: 9.4695 - accuracy: 0.3824 - val_loss: 10.1662 - val_accuracy: 0.3333\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"# Answer below:\\nmodel = build_model(X.shape[1], output_dim=y.shape[1], layer_nodes=[128,64,32,32], activation_function='relu', output_function='sigmoid')\\nmodel.compile(loss='binary_crossentropy',optimizer=rms, metrics=['accuracy'] )\\nhistory = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=100, epochs=200)\";\n",
       "                var nbb_formatted_code = \"# Answer below:\\nmodel = build_model(\\n    X.shape[1],\\n    output_dim=y.shape[1],\\n    layer_nodes=[128, 64, 32, 32],\\n    activation_function=\\\"relu\\\",\\n    output_function=\\\"sigmoid\\\",\\n)\\nmodel.compile(loss=\\\"binary_crossentropy\\\", optimizer=rms, metrics=[\\\"accuracy\\\"])\\nhistory = model.fit(\\n    X_train, y_train, validation_data=(X_test, y_test), batch_size=100, epochs=200\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Answer below:\n",
    "model = build_model(X.shape[1], output_dim=y.shape[1], layer_nodes=[128,64,32,32], activation_function='relu', output_function='sigmoid')\n",
    "model.compile(loss='binary_crossentropy',optimizer=rms, metrics=['accuracy'] )\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=100, epochs=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"pd.DataFrame(history.history)[[\\\"accuracy\\\", \\\"val_accuracy\\\"]].plot()\";\n",
       "                var nbb_formatted_code = \"pd.DataFrame(history.history)[[\\\"accuracy\\\", \\\"val_accuracy\\\"]].plot()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)[[\"accuracy\", \"val_accuracy\"]].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E3KhWb3igGv1"
   },
   "source": [
    "Define the Adam optimizer with learning rate 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ewtmWJI3gGv1"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"# Answer below:\\nadam = Adam(learning_rate=0.01)\";\n",
       "                var nbb_formatted_code = \"# Answer below:\\nadam = Adam(learning_rate=0.01)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Answer below:\n",
    "adam = Adam(learning_rate=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lnxqbb7CgGv3"
   },
   "source": [
    "Compile and fit the model using the optimizer defined above. How does the peformance differ with this optimizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rG9-9Nk4gGv3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 455 samples, validate on 114 samples\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-55f1b82830b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"binary_crossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0madam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m history = model.fit(\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_select_training_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 790\u001b[1;33m     return func.fit(\n\u001b[0m\u001b[0;32m    791\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    647\u001b[0m       \u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_sample_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 649\u001b[1;33m     return fit_loop(\n\u001b[0m\u001b[0;32m    650\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    268\u001b[0m       \u001b[1;31m# Collecting and resetting metrics has non-zero cost and will needlessly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    269\u001b[0m       \u001b[1;31m# slow down model.predict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 270\u001b[1;33m       \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    271\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\u001b[0m in \u001b[0;36mreset_metrics\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    996\u001b[0m     \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_training_eval_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    997\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 998\u001b[1;33m       \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    999\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1000\u001b[0m     \u001b[1;31m# Reset metrics on all the distributed (cloned) models.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\metrics.py\u001b[0m in \u001b[0;36mreset_states\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    245\u001b[0m     \u001b[0mwhen\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmetric\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mevaluated\u001b[0m \u001b[0mduring\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m     \"\"\"\n\u001b[1;32m--> 247\u001b[1;33m     \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabstractmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[1;34m(tuples)\u001b[0m\n\u001b[0;32m   3599\u001b[0m           \u001b[0massign_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3600\u001b[0m           \u001b[0mfeed_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3601\u001b[1;33m         \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3603\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mget_session\u001b[1;34m(op_input_list)\u001b[0m\n\u001b[0;32m    628\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 630\u001b[1;33m       \u001b[0m_initialize_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    631\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[1;34m(session)\u001b[0m\n\u001b[0;32m   1050\u001b[0m     \u001b[1;31m# This step is expensive, so we only run it on variables not already\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1051\u001b[0m     \u001b[1;31m# marked as initialized.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1052\u001b[1;33m     is_initialized = session.run(\n\u001b[0m\u001b[0;32m   1053\u001b[0m         [variables_module.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0;32m   1054\u001b[0m     \u001b[1;31m# TODO(kathywu): Some metric variables loaded from SavedModel are never\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 957\u001b[1;33m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[0;32m    958\u001b[0m                          run_metadata_ptr)\n\u001b[0;32m    959\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;31m# or if the call is a partial run that specifies feeds.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[0;32m   1181\u001b[0m                              feed_dict_tensor, options, run_metadata)\n\u001b[0;32m   1182\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1358\u001b[1;33m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[0;32m   1359\u001b[0m                            run_metadata)\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1363\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1346\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m   1350\u001b[0m                                       target_list, run_metadata)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1386\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1387\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1388\u001b[1;33m       \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1390\u001b[0m   \u001b[1;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"# Answer below:\\nmodel = build_model(\\n    X.shape[1],\\n    output_dim=y.shape[1],\\n    layer_nodes=[128, 64, 32, 32],\\n    activation_function=\\\"relu\\\",\\n    output_function=\\\"sigmoid\\\",\\n)\\n\\nmodel.compile(loss=\\\"binary_crossentropy\\\", optimizer=adam, metrics=[\\\"accuracy\\\"])\\nhistory = model.fit(\\n    X_train, y_train, validation_data=(X_test, y_test), batch_size=100, epochs=200\\n)\";\n",
       "                var nbb_formatted_code = \"# Answer below:\\nmodel = build_model(\\n    X.shape[1],\\n    output_dim=y.shape[1],\\n    layer_nodes=[128, 64, 32, 32],\\n    activation_function=\\\"relu\\\",\\n    output_function=\\\"sigmoid\\\",\\n)\\n\\nmodel.compile(loss=\\\"binary_crossentropy\\\", optimizer=adam, metrics=[\\\"accuracy\\\"])\\nhistory = model.fit(\\n    X_train, y_train, validation_data=(X_test, y_test), batch_size=100, epochs=200\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Answer below:\n",
    "model = build_model(\n",
    "    X.shape[1],\n",
    "    output_dim=y.shape[1],\n",
    "    layer_nodes=[128, 64, 32, 32],\n",
    "    activation_function=\"relu\",\n",
    "    output_function=\"sigmoid\",\n",
    ")\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=adam, metrics=[\"accuracy\"])\n",
    "history = model.fit(\n",
    "    X_train, y_train, validation_data=(X_test, y_test), batch_size=100, epochs=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history)[[\"accuracy\", \"val_accuracy\"]].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1opnI2qCgGv5"
   },
   "source": [
    "Now change the learning rate to 0.1 in your Adam optimizer and compare the results (both speed and accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aIGTzU1DgGv6"
   },
   "outputs": [],
   "source": [
    "# Answer below:\n",
    "\n",
    "adam = Adam(learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e91KQiHqgGv7"
   },
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    X.shape[1],\n",
    "    output_dim=y.shape[1],\n",
    "    layer_nodes=[128, 64, 32, 32],\n",
    "    activation_function=\"relu\",\n",
    "    output_function=\"sigmoid\",\n",
    ")\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=adam, metrics=[\"accuracy\"])\n",
    "history = model.fit(\n",
    "    X_train, y_train, validation_data=(X_test, y_test), batch_size=100, epochs=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history)[[\"accuracy\", \"val_accuracy\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Day 78 Lecture 2 Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
